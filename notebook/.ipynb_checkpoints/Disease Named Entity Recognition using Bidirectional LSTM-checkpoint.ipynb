{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disease named entity recognition using bidirectional recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import unicodedata\n",
    "import project_path\n",
    "import lib\n",
    "import utils\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants \n",
    "PAD_LENGTH=180 \n",
    "LSTM_UNITS=120 \n",
    "BATCH_SIZE=48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train and test datasets\n",
    "train_data = pd.read_csv(\"train.csv\", encoding=\"latin1\")\n",
    "test_data = pd.read_csv(\"test.csv\",encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag\n",
       "0   1       1        1        Obesity   O\n",
       "1   2       1        1             in   O\n",
       "2   3       1        1           Low-   O\n",
       "3   4       1        1            and   O\n",
       "4   5       1        1  Middle-Income   O"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4543834</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>CCCVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4543835</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4543836</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>MANOVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4543837</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4543838</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Doc_ID  Sent_ID    Word\n",
       "0  4543834   30001   191283   CCCVA\n",
       "1  4543835   30001   191283       ,\n",
       "2  4543836   30001   191283  MANOVA\n",
       "3  4543837   30001   191283       ,\n",
       "4  4543838   30001   191283      my"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         4543833\n",
       "Doc_ID       30000\n",
       "Sent_ID     191282\n",
       "Word        184505\n",
       "tag              3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of unique docs, sentences and words in training data\n",
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         2994463\n",
       "Doc_ID       20000\n",
       "Sent_ID     125840\n",
       "Word        139891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of unique docs, sentences and words in test data\n",
    "test_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of word dictionary:  257203\n",
      "Length of tag dictionary:  3\n"
     ]
    }
   ],
   "source": [
    "#Creating dictionaries of unique words and tags\n",
    "words=list(set(train_data[\"Word\"].append(test_data[\"Word\"]).values)) #removing duplicate entries using set\n",
    "words.append(\"ENDPAD\")  \n",
    "tags=list(set(train_data[\"tag\"].values)) \n",
    "\n",
    "\n",
    "len_words=len(words)\n",
    "\n",
    "len_tags=len(tags) \n",
    "\n",
    "print(\"Length of word dictionary: \",len_words)\n",
    "print(\"Length of tag dictionary: \",len_tags) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing \n",
    "#Convert greek characters to ASCII characters\n",
    "words=[unicodedata.normalize('NFKD',str(w)).encode('ascii','ignore') for w in words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionaries that has all unique words/tags as keys and unique ID as values\n",
    "word2idx=dict(zip(words,range(0,len_words-1))) \n",
    "tag2idx=dict(zip(tags,range(0,len_tags-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'nan': 0, b'detoxifying': 1, b'Operability': 2}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(word2idx.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-indications': 0, 'O': 1}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(tag2idx.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Obesity', 'O'), ('in', 'O'), ('Low-', 'O'), ('and', 'O'), ('Middle-Income', 'O'), ('Countries', 'O'), (':', 'O'), ('Burden', 'O'), (',', 'O'), ('Drivers', 'O'), (',', 'O'), ('and', 'O'), ('Emerging', 'O'), ('Challenges', 'O'), ('.', 'O')], [('We', 'O'), ('have', 'O'), ('reviewed', 'O'), ('the', 'O'), ('distinctive', 'O'), ('features', 'O'), ('of', 'O'), ('excess', 'O'), ('weight', 'O'), (',', 'O'), ('its', 'O'), ('causes', 'O'), (',', 'O'), ('and', 'O'), ('related', 'O'), ('prevention', 'O'), ('and', 'O'), ('management', 'O'), ('efforts', 'O'), (',', 'O'), ('as', 'O'), ('well', 'O'), ('as', 'O'), ('data', 'O'), ('gaps', 'O'), ('and', 'O'), ('recommendations', 'O'), ('for', 'O'), ('future', 'O'), ('research', 'O'), ('in', 'O'), ('low-', 'O'), ('and', 'O'), ('middle-income', 'O'), ('countries', 'O'), ('(', 'O'), ('LMICs', 'O'), (')', 'O'), ('.', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "#Get training sentences in a list\n",
    "train_sentences = get_tagged_sentences(train_data) \n",
    "print(train_sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CCCVA', ',', 'MANOVA', ',', 'my', 'black', 'hen', '.'], ['Comments', 'on', 'repeated', 'measures', '.']]\n"
     ]
    }
   ],
   "source": [
    "#Get test sentences in a list\n",
    "test_sentences=get_test_sentences(test_data)\n",
    "print(test_sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction for DL\n",
    "#Convert words to indices for train and test sentences. Also convert greek characters to ASCII characters\n",
    "X_train = [[word2idx[unicodedata.normalize('NFKD', str(w[0])).\n",
    "               encode('ascii','ignore')] for w in s] for s in train_sentences]\n",
    "X_test = [[word2idx[unicodedata.normalize('NFKD', str(w)).\n",
    "                    encode('ascii','ignore')] for w in s] for s in test_sentences]\n",
    "\n",
    "\n",
    "#Pad train and test sentences to PAD_LENGTH(180 words)\n",
    "X_train=pad_sequences(maxlen=PAD_LENGTH,sequences=X_train,padding=\"post\",value=len_words-1)\n",
    "X_test=pad_sequences(maxlen=PAD_LENGTH,sequences=X_test,padding=\"post\",value=len_words-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert tags to indices for train sentences\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "# Creating tags to indices dictionary.\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "y = [[tag2idx[w[1]] for w in s] for s in train_sentences]\n",
    "#Pad tag labels to PAD_LENGTH(180 words)\n",
    "y=pad_sequences(maxlen=PAD_LENGTH,sequences=y,padding=\"post\",value=tag2idx[\"O\"])\n",
    "\n",
    "#One hot encode labels\n",
    "y=[to_categorical(i,num_classes=len_tags)for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input layer with input of 180 dimensional word indices \n",
    "input = Input(shape=(PAD_LENGTH,)) \n",
    "\n",
    "#Embedding layer \n",
    "model=Embedding(input_dim=len_words,output_dim=PAD_LENGTH,input_length=PAD_LENGTH)(input)\n",
    "\n",
    "#Adding dropout layer\n",
    "model=Dropout(0.2)(model) \n",
    "\n",
    "#Bidirectional LSTM layer \n",
    "model=Bidirectional(LSTM(units=LSTM_N,return_sequences=True,recurrent_dropout=0.1))(model) \n",
    "\n",
    "#Time distributed dense layer \n",
    "output=TimeDistributed(Dense(n_tags,activation=\"softmax\"))(model) #Softmax output layer\n",
    "\n",
    "model=Model(input,output)\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy,metrics=[\"accuracy\",\"mean_absolute_error\"])\n",
    "history=model.fit(X_train,np.array(y),batch_size=BATCH_SIZE,epochs=2,validation_split=0.05,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
